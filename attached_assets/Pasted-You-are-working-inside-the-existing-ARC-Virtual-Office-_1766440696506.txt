You are working inside the existing ARC Virtual Office project on Replit.

Goal: verify (with hard evidence) whether the operational loop is fully closed:
Trigger → Receive → Execute → Proof → Daily Summary.

Do NOT do any broad refactors. Do NOT change unrelated code. Minimal changes only.
Do NOT expose secrets in logs or responses.

TASK A — Add an evidence-first E2E verifier script
1) Create a new file in project root: arc_e2e_verifier.js
2) The script must:
   - Read env vars:
     ARC_BASE_URL (default http://127.0.0.1:5000)
     ARC_BACKEND_SECRET (required for protected endpoints)
     DATABASE_URL (optional, for DB proof)
   - Generate a unique run_id (timestamp + random)
   - Call these endpoints and record full details:
     GET /api/health
     GET /ping
     GET /api/arc/reality-report
     GET /api/arc/status
     POST /api/arc/agent-events with payload {agent_name:"e2e_verifier", event_type:"E2E_PROBE_EVENT", payload:{run_id,at,source}}
     POST /api/arc/receive with payload including required field source (use "e2e_verifier")
     POST /arc/execute with payload {run_id, command:"ARC>E2E_EXECUTE", payload:{at,note}}
   - For each call: store status, ok, headers (redact secrets), and body preview + JSON if parseable.
   - If DATABASE_URL is present and pg is available:
       * connect to Postgres
       * confirm total tables count
       * confirm the inserted event exists in agent_events table by searching payload for run_id
       * output proof with row id(s)
   - Write ONE JSON result file in project root: arc_e2e_verifier_<run_id>.json
   - Print a final verdict PASS/FAIL:
       PASS only if:
         - /api/health and /ping are 200
         - /api/arc/agent-events is 200 and DB proof exists when DB is enabled
         - /api/arc/receive is not 401 (200 or 400 validation is acceptable)
         - /arc/execute is NOT 500 and returns a structured proof object (execution_id at minimum)
       Otherwise FAIL with explicit reasons.

TASK B — Fix /arc/execute to close the loop (minimal, evidence-based)
Current reality: /arc/execute returns 500 "server_misconfigured" because the executor is missing.
Implement the minimal execution path:

1) /arc/execute should:
   - Require ARC_BACKEND_SECRET via header (x-arc-secret or x_arc_secret) and reject otherwise (401).
   - Require N8N_WEBHOOK_URL env var.
   - Forward the incoming command payload to N8N_WEBHOOK_URL (POST JSON).
   - Wait for n8n response (with timeout).
   - Create an execution proof record in DB (if DB is available via existing DB layer) OR store proof in an existing table (action_log/result_log/command_logs; choose the most appropriate existing table).
   - Return JSON:
     { ok:true, run_id, execution_id, n8n_status, stored_table, stored_row_id, server_timestamp }

2) If N8N_WEBHOOK_URL missing, return 500 with clear error: "server_misconfigured" and include missing field name.
3) Do NOT break existing routes. Keep changes localized to the execute handler and any helper.
4) Add basic retry (1 retry) for transient network errors to n8n.

TASK C — Daily summary generation (minimal stub if full summary exists)
1) Add endpoint /api/arc/generate-summary (protected by secret)
2) It should:
   - Pull the latest N events from agent_events and latest N executions from the execution proof table.
   - Generate a compact executive summary (can be deterministic text first; if OpenAI is available, use it, but must gracefully fallback).
   - Store it in an existing table for summaries (executive_summaries if exists; otherwise create a minimal table).
   - Return {ok:true, summary_id, stored:true}

DELIVERABLES
- Commit only the required files/changes.
- After implementation:
  1) Run: ARC_BASE_URL="http://127.0.0.1:5000" ARC_BACKEND_SECRET="<secret>" DATABASE_URL="$DATABASE_URL" node arc_e2e_verifier.js
  2) Paste the final PASS/FAIL output and the path to the JSON file.
  3) Show evidence that /arc/execute now returns ok:true with execution_id and DB stored row id.
