You are operating inside my Replit project (ARC Intelligence Framework + X Bio Sentinel).

STRICT RULES (MANDATORY):
- Do NOT remove any endpoints.
- Do NOT delete or modify any existing DB tables/columns. Additive changes only.
- Do NOT rename routes/paths.
- Any instrumentation/logging must be gated by a VALID ARC secret header (x_arc_secret OR x-arc-secret).
- Before editing anything: produce a FULL INVENTORY (file/folder map) + a PRE-EXECUTION CHANGE SPEC (Markdown) for approval.
- Execution order is MANDATORY and must be followed exactly.
- After EACH step: report (1) files changed, (2) endpoints added/changed, (3) how to test (curl + UI path).

CONTEXT (current known state):
- Auth header compatibility already added (x_arc_secret canonical + x-arc-secret legacy).
- /api/arc/receive + ingest endpoints exist.
- /arc/execute was converted to a real command router (not placeholder).
- Causal memory tables exist: intent_log, action_log, result_log, impact_log + endpoints.
- reflections table + /api/core/reflect, /api/core/reflections exist.
- agent contracts exist: arc_core/agent_contracts.json + server/contracts.ts middleware.
- There is still a need for “LIVE CORE STABILIZATION” and a REAL inventory of attached assets/folders, plus verifying what is truly used vs unused.

GOAL:
Deliver a “LIVE CORE STABILIZATION” pass that makes the system operationally clear, observable, and reduces mock/legacy surfaces—WITHOUT breaking anything.

========================
STEP 0 — FULL INVENTORY / FILE MAP (READ-ONLY)
Produce a FACTUAL Markdown inventory report with:
1) Root tree (folders/files) and purpose of each major folder.
2) Client pages/routes list:
   - route path
   - file path
   - backend endpoint dependencies
   - whether it’s REAL data, MOCK, or DOC-only
3) Backend endpoints list:
   - group by category (auth, core, arc ingest, dashboard, team, bio-sentinel, contracts, analytics)
   - mark: used by UI / used by n8n / internal only / unused
4) Database tables list (from shared/schema.ts + drizzle):
   - mark actively used vs likely unused
5) Attached assets inventory:
   - FULL listing of attached_assets/ and any “archives/ reports/ docs/ firmware/ android/” payloads
   - flag anything not referenced anywhere in code (grep-based evidence)
6) Integration inventory:
   - OpenAI, ElevenLabs, n8n inbound/outbound, Supabase legacy, Twilio, Telegram
   - for each: is it actually used in runtime? where? what endpoint? what secret?

IMPORTANT:
- For attached_assets: include approximate file sizes and file types and whether referenced in code.
- Provide “UNUSED / LEGACY / DUPLICATE” section with hard evidence (file not imported, route not linked, etc).

STOP after STEP 0 and wait for my “APPROVED” to execute changes.

========================
STEP 1 — LIVE STATUS ENDPOINT + UI PANEL (ADD ONLY)
Implement a minimal operational status surface:
A) Backend: add GET /api/live/status
- Must require valid ARC secret header.
- Response returns: auth ok, db ok+latency, websocket ok, n8n ok (only if configured), telegram status, supabase legacy status.
- Mask secrets (never return tokens/keys).
B) Frontend: add a small LiveStatusPanel component displayed on Home or Dashboard.
- Show badges for: DB, WebSocket, n8n, OpenAI, ElevenLabs, Telegram.
- If something is missing, show reason (e.g., “telegram not configured”, “n8n webhook unreachable”).

Provide curl tests + UI path to verify.

========================
STEP 2 — REMOVE MOCK/LEGACY SURFACES (MINIMUM)
- Identify any pages still using mock data (e.g., /metrics or any placeholder charts).
- Replace with existing real endpoints if available (prefer /api/dashboard/metrics etc).
- If a real endpoint is missing AND needed, add a new endpoint (additive) to supply the same data.
- DO NOT delete duplicate pages yet; only mark duplicates clearly in the report.

Provide before/after proof (what was mock, what is now real).

========================
STEP 3 — TELEGRAM RESTORE (FAST PATH)
Current: Telegram bot stopped.
Do NOT build a full bot unless token exists.
Implement fastest reliable path:
- Add /arc/execute command: send_telegram
- Behavior: emits to n8n via existing outbound mechanism (N8N_WEBHOOK_URL) with payload type "telegram_send" and message.
- If N8N_WEBHOOK_URL missing/unreachable, return ok:false with reason.
- Add minimal server-side validation and causal logging (intent/action/result).
Also add an ingest endpoint (if not already) for telegram delivery receipts from n8n: POST /api/arc/telegram/receipt (header-gated).
(If endpoint already exists, keep it; do not replace.)

Provide exact n8n expected payload schema.

========================
STEP 4 — N8N TWO-WAY CONFIRMATION (NO ASSUMPTIONS)
Because n8n AI reports were contradictory:
- Do not infer workflows.
- Add a backend endpoint GET /api/arc/n8n/handshake that returns expected routes + schemas.
- Provide a test plan to validate from n8n side using a single HTTP Request node.
No change to n8n itself, only backend support.

========================
DELIVERABLES FORMAT (MANDATORY):
1) STEP 0 inventory report (Markdown)
2) PRE-EXECUTION CHANGE SPEC for Steps 1–4 (Markdown) including:
   - files to change
   - endpoints added/changed
   - DB impact (should be none or additive only)
   - security impact
   - test plan (curl + UI)
   - rollback plan (checkpoint instructions)
3) Only after I say “APPROVED”: execute Steps 1–4 sequentially, reporting after each.

Start NOW with STEP 0 only.
